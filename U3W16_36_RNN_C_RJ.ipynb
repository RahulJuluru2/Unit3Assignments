{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulJuluru2/unit3assignments/blob/main/U3W16_36_RNN_C_RJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9k5heqzZ6CP"
      },
      "source": [
        "\n",
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-ObRs5nPoAR"
      },
      "source": [
        "### Learning Objectives "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqK4U4dRP1H7"
      },
      "source": [
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "1.   Generate text which is similar to the writing style of William Shakespeare\n",
        "2.   Understand how to adapt or tune the trained network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EHmt3YzitsW3"
      },
      "outputs": [],
      "source": [
        "#@title Experiment Explanation Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"800\" height=\"300\" controls>\n",
        "  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/module_3_week_12_experiment_1.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abu-cNx8imcT"
      },
      "source": [
        "### Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rXIJFmjoBdi"
      },
      "source": [
        "####  Description\n",
        "\n",
        "The dataset used in this experiment has partial content of different plays of Shakespeare concatenated into a single plain text file. \n",
        "\n",
        "Shakespeare is a famous English poet , play writer and actor. He is regarded as the greatest writer in the English language and the world's greatest dramatist. He is often called a England's national poet and the Bard of Avon. \n",
        "\n",
        "We have chosen plays of Shakespeare as our dataset mainly for two reasons : \n",
        "\n",
        "1. His work is widely recognized as standard for poetry and language.\n",
        "2. The result of combining of his work provides a sizeable corpus for our model to learn.\n",
        "\n",
        "The plays of Shakespeare are taken from the following url:\n",
        "\n",
        "www.opensourceshakespeare.org/views/plays/plays.php\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEQTPQUWiRZi"
      },
      "source": [
        "### Domain Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rsRsHXeiivc"
      },
      "source": [
        "Music and Art are considered creative in nature and creating them is assumed to be more difficult when compared to writing a book, article or text. But the reality is that creating music and art is less complicated because there are no strict rules like which direction should one paint in or when to pause between the notes. However,  while writing a text one must follow grammatical rules. Hence, writing/generating text task is more related to machine learning and artificial intelligence.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE8bAdSkwUt3"
      },
      "source": [
        "### AI/ML Technique \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOs7dwuIZ6CT"
      },
      "source": [
        "The RNN algorithm is used to generate text which is similar to the writing style of Shakespeare. Let us try to understand the main idea behind using this algorithm.\n",
        "\n",
        "#### RNN algorithm\n",
        "\n",
        "The main idea is to use sequential information. In a traditional neural network we assume that all inputs (and outputs) are independent of each other. But for many tasks that’s a bad idea. If you want to predict the next word in a sentence you better know which words came before it. This is possible through RNN. RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being depended on the previous computations. \n",
        "\n",
        "*Example:*  Take an example string **“HELLO”**. The vocabulary of the example is made of four letters or characters H,E,L,O. Now, let us apply RNN algorithm on this.\n",
        "\n",
        "Give *'H'* as input to the trained RNN model, it would give us an output *'E'*. In the next stage, this output *'E'* is passed as the new input which would give us the new output *'L'*. As the cycle follows, this output *'L'* is the new input but then what do you think the new output should be, second *‘L’* or *‘O’*? This is the challenge in predicting the next letter or character which RNN can solve. RNN has its own memory which helps it to predict based on the previous characters in this case H, E and L. Hence the output would most probably be *'L'* and not *'O'*.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAFJ2xOxmPAR"
      },
      "source": [
        "![alt text](https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/7.1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj_Bik_GtTml"
      },
      "source": [
        "In this experiment we will follow below steps:\n",
        "\n",
        "1.   Preparing the data\n",
        "2.   Building the model\n",
        "3.   Defining helper functions\n",
        "4.   Training the model\n",
        "5.    Adapting or Fine-tuning for text generation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mai03dwIgRGG"
      },
      "source": [
        "### Setup Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lXnlnkgBAxBS"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your registration id to start:  { run: \"auto\", display-mode: \"form\" }\n",
        "Id= \"2216842\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rokxRCMLAzWU"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password= \"9959488784\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "-ChfY8GTH3SB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab31cd55-007b-4551-aac8-bc6538b6214a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2216842&recordId=2778\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ],
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook= \"U3W16_36_RNN_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\") \n",
        "    ipython.magic(\"sx pip3 install torch\")\n",
        "    ipython.magic(\"sx pip3 install Unidecode\")\n",
        "    ipython.magic(\"sx pip3 install unidecode\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week10/Exp1/shakespeare.txt\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "    \n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "  \n",
        "  \n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "  \n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup() \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBrFphh3mCTk"
      },
      "source": [
        "### Importing required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "11e72PpPZ6Ca"
      },
      "outputs": [],
      "source": [
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import time, math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3HMm0p-Z6CX"
      },
      "source": [
        "### 1. Preparing the Data\n",
        "\n",
        "The file here is a plain text file. By using the [unidecode](https://pypi.org/project/Unidecode/) package turn any potential unicode characters into plain ASCII"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sE5njLNJZ6Cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f9e19e5-f9bd-4065-bdcd-c3df1de1fc26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_len = 1115393\n"
          ]
        }
      ],
      "source": [
        "# Code to extract all sets of punctuation, digits, ascii_letters and whitespace characters\n",
        "all_characters = string.printable\n",
        "\n",
        "# Code to find length of all_characters and storing the value in n_characters\n",
        "n_characters = len(all_characters)\n",
        "\n",
        "# Use unidecode to convert unicode characters into plain ASCII\n",
        "file = unidecode.unidecode(open('shakespeare.txt').read())\n",
        "\n",
        "# Code to find length of the file\n",
        "file_len = len(file)\n",
        "\n",
        "# Printing the length of the file\n",
        "print('file_len =', file_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlqTfzzxwvaU"
      },
      "source": [
        "The variable 'file' is a string with 1115393 characters. This is the raw content of the Shakespeare text file (dataset file), including many details like white spaces, line breaks etc. \n",
        "\n",
        "Now to get the sense of the data we print first 1000 characters in the string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gM3NTD74Z6Cp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "0ccd45a7-27c8-4b61-9157-a7118ea7b23c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "file[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BfQ1VWCZ6Cw"
      },
      "source": [
        "As the string is large, split it into chunks to provide inputs to the RNN using the function random_chunk()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1TffxtFCZ6Cz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce1a4c6-d1ba-49cf-a932-d72da256dbfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " shall we hear their 'larum, and they ours.\n",
            "Now, Mars, I prithee, make us quick in work,\n",
            "That we with smoking swords may march from hence,\n",
            "To help our fielded friends! Come, blow thy blast.\n",
            "Tutus Aufid\n"
          ]
        }
      ],
      "source": [
        "# Initialization of the chunk length for the number of RNN's in a particular length, so that it can recall up to 200 timesteps backwards.\n",
        "chunk_len = 200\n",
        "\n",
        "# Function to split the string into chunks\n",
        "def random_chunk():\n",
        "    \n",
        "    # Initializing the starting index value of the big string \n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "\n",
        "    # Initializing the ending index of the string \n",
        "    end_index = start_index + chunk_len + 1\n",
        "\n",
        "    # Returning the chunk\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "# Printing the random chunk string\n",
        "print(random_chunk())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V__BZbmmd-jT"
      },
      "source": [
        "###  2. Building the Model\n",
        "\n",
        "This model will take input as the character for step $t_{-1}$, and is expected to give the output $t$, which is the next character. There are three layers:\n",
        "1. Linear layer that encodes the input character into an internal state\n",
        "2. GRU layer (which may itself have multiple layers) that operates on that internal and hidden state.\n",
        "    - If you want to try for RNN, just replace the nn.GRU with nn.RNN. Refer to RNN link [RNN](https://pytorch.org/docs/master/generated/torch.nn.RNN.html) \n",
        "3. Decoder layer that outputs the probability distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3h1GIrjHZ6C9"
      },
      "outputs": [],
      "source": [
        "# Creating recurrent neural network\n",
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers) # If you want to use RNN you can replace GRU with RNN and see the results\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, hidden = self.gru(input.view(1, 1, -1), hidden) # Change self.gru to self.rnn if you are constructing the RNN layer\n",
        "        output = self.decoder(output.view(1, -1))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # Here we are Initializing the hidden layer to zero everytime\n",
        "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP3H8LiSZ6DC"
      },
      "source": [
        "### 3. Defining the Helper Functions\n",
        "\n",
        "Let us define some helper functions to:\n",
        "\n",
        "1. Convert the input string chunks into the character tensors\n",
        "2. Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpWdV9iEZ6DD"
      },
      "source": [
        "#### Inputs and Targets\n",
        "Each chunk will be turned into a tensor, specifically a LongTensor (used for integer values), by looping through the characters of the string and looking up the index of each character in all_characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_j2hxN7QZ6DF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c9270e-e328-486f-c4e4-186c30b05f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ]
        }
      ],
      "source": [
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)\n",
        "\n",
        "# Let us print the tensor value for a given sample string, you can modify the string here...\n",
        "print(char_tensor('abcDEF'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrottX4SZ6DL"
      },
      "source": [
        "Finally you assemble a pair of input and target tensors for training, from a random chunk. The input will be all characters up to the end, and the target will be all characters from the first. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "siN-Z8X_Z6DN"
      },
      "outputs": [],
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4QPs5BqZ6DS"
      },
      "source": [
        "#### Evaluating\n",
        "\n",
        "To evaluate the network feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation pass a priming string to start building up the hidden state, from which you then generate one character at a time.\n",
        "\n",
        "In the below function let us assign the default primary string as 'A' and to choose a class with a probability output use the [muiltinomial distribution](https://pytorch.org/docs/master/generated/torch.multinomial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "v2m-JfwXZ6DW"
      },
      "outputs": [],
      "source": [
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "    hidden = rnn.init_hidden()\n",
        "    prime_input = char_tensor(prime_str)\n",
        "    predicted = prime_str\n",
        "\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = rnn(prime_input[p], hidden)\n",
        "    inp = prime_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden = rnn(inp, hidden)\n",
        "        \n",
        "        # Applying Softmax & Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = char_tensor(predicted_char)\n",
        "\n",
        "    return predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZVmbuZ4Z6De"
      },
      "source": [
        "### 4. Training the Model\n",
        "\n",
        "To keep track of how long training takes, let us add a time_since(timestamp) function which returns a human readable string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rFevLn43Z6Dh"
      },
      "outputs": [],
      "source": [
        "# Function to print amount of time passed\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXqylIRyZ6Dn"
      },
      "source": [
        "#### The main training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "n3vWoTsxZ6Dp"
      },
      "outputs": [],
      "source": [
        "def train(inp, target):\n",
        "    # Initialize the hidden representation, gradient, loss to zeros\n",
        "    hidden = rnn.init_hidden()\n",
        "    rnn.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(chunk_len):\n",
        "        output, hidden = rnn(inp[c], hidden)\n",
        "        '''unsqueeze() is used to add dimension to the tensor'''\n",
        "        loss += criterion(output, target[c].unsqueeze(dim=0))\n",
        "    # Back propagation\n",
        "    loss.backward()\n",
        "    rnn_optimizer.step()\n",
        "\n",
        "    return loss.item() / chunk_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB-y61RZZ6Dt"
      },
      "source": [
        "Then define the training parameters, instantiate the model, and start training. In the below cell  try to print the chunk, loss and time taken for every 50th iteration and for every 20th iteration  try to plot the loss vs epochs(iterations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPG6aUEeZ6Du",
        "outputId": "1ea22847-35cf-48c9-885c-c770af4fc452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0m 5s (50 2%) 2.4586]\n",
            "Whe moute, dourd fomete thom er col the hes the my nor theaks thant he in tfe OHSo thersthe lonml bur  \n",
            "\n",
            "[0m 10s (100 5%) 2.4593]\n",
            "Whes at hour tha and'k mavenglard all of the our hard\n",
            "Eowionl thit ay so mallen lond blon;ed mot thou, \n",
            "\n",
            "[0m 15s (150 7%) 2.1685]\n",
            "Whirstest you thou any.\n",
            "\n",
            "Ther helef for to wer or\n",
            "So moy cothiby sont ofost\n",
            "Te\n",
            "The pirs thes,\n",
            "Thing be \n",
            "\n",
            "[0m 20s (200 10%) 2.2525]\n",
            "Why singond noropall torle:\n",
            "And's wely same, wartin my the kinge, all'se,\n",
            "Shas the sepeard she to yera \n",
            "\n",
            "[0m 30s (250 12%) 1.9324]\n",
            "Whe than ras, here sas; part poustance,\n",
            "And coom\n",
            "Bally not lowh the dond of all hessence\n",
            "And shune in  \n",
            "\n",
            "[0m 35s (300 15%) 2.2383]\n",
            "Wht, the bence fall;\n",
            "For to the lam thee that staye thien. your of I preapter fordal slans, with untou \n",
            "\n",
            "[0m 41s (350 17%) 1.8683]\n",
            "Whe to best the mon to that thom ous piting ming of to hein for staring sase an a do wartare matire.\n",
            "\n",
            " \n",
            "\n",
            "[0m 46s (400 20%) 1.9870]\n",
            "Whiss, it cment be maddy, and may thich thattime por-.\n",
            "\n",
            "QUEENEN':\n",
            "Thou kith, Of Lorver yor, shere!\n",
            "\n",
            "FO \n",
            "\n",
            "[0m 51s (450 22%) 2.0758]\n",
            "Whus in the wall ford bothee and in up your stay,\n",
            "Cleak Lord the coual that meep,\n",
            "Maderis no menonding \n",
            "\n",
            "[0m 56s (500 25%) 2.0890]\n",
            "Whis there and all dother.\n",
            "\n",
            "CORELES:\n",
            "Shich as are the is there this it to prined:\n",
            "Thy at min, live for \n",
            "\n",
            "[1m 1s (550 27%) 1.7414]\n",
            "Whight of ind.\n",
            "\n",
            "COLIZARD:\n",
            "Gome, toerse that as Wast\n",
            "Thevere, make ald disur a was so,\n",
            "To hast wishens  \n",
            "\n",
            "[1m 6s (600 30%) 1.7167]\n",
            "Whis vere\n",
            "Tamn that of love trouthen my Fime, in that than will of to sour thaten\n",
            "And by wasprerentie  \n",
            "\n",
            "[1m 11s (650 32%) 2.1610]\n",
            "Whal shath'm be no park'd:\n",
            "Then of I love theke one will to and hing Hir\n",
            "Four it thy speitisen, sire n \n",
            "\n",
            "[1m 16s (700 35%) 1.9658]\n",
            "Wht and prins.\n",
            "\n",
            "KING ERIIZAS:\n",
            "So a live, live, forts to fill why\n",
            "And in yourch thou fikens, with,\n",
            "Lous \n",
            "\n",
            "[1m 21s (750 37%) 1.5916]\n",
            "Wht sight, read, sir, and in you look leses to will to stay my lord,\n",
            "Aster, cablow for that ald a dove \n",
            "\n",
            "[1m 26s (800 40%) 1.8026]\n",
            "Which worthous them wan.\n",
            "Whalt my a ceen ends to doon ray,\n",
            "O, by wother, I brant wonch sone no for I f \n",
            "\n",
            "[1m 32s (850 42%) 1.8174]\n",
            "Wh our spitity, the comn\n",
            "You paik you makner, a so making to is hile proshid, shing not;\n",
            "And the rught \n",
            "\n",
            "[1m 37s (900 45%) 2.1029]\n",
            "What for hath love to the sands thee;\n",
            "Fir live to besoly.\n",
            "\n",
            "MENENIUS:\n",
            "We rakiin'd be raite mass, lies,  \n",
            "\n",
            "[1m 42s (950 47%) 2.1516]\n",
            "What not rath well dike\n",
            "This thy prong.\n",
            "Mould yemes my hevere my proodes them my molanitle hence you m \n",
            "\n",
            "[1m 47s (1000 50%) 2.0434]\n",
            "Whe compen beat in my hay,\n",
            "I shourt wonded is or of ine:\n",
            "Then thy do hirt he cournemes not man,\n",
            "You wi \n",
            "\n",
            "[1m 52s (1050 52%) 2.1481]\n",
            "When, your seris dies the not.\n",
            "\n",
            "ANGLEO:\n",
            "Now main a make sage again us thou and you.\n",
            "\n",
            "SPETBANUT:\n",
            "Who lo \n",
            "\n",
            "[1m 57s (1100 55%) 1.7169]\n",
            "Where, his thour who seet her like I but day, whom madion,\n",
            "I sumestly hath thiens, swor some, be this  \n",
            "\n",
            "[2m 2s (1150 57%) 1.9797]\n",
            "Whom as is where subly broth chair.\n",
            "\n",
            "DUKE VONSTIO:\n",
            "As lith do my the lond.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "That misan \n",
            "\n",
            "[2m 7s (1200 60%) 1.8389]\n",
            "Wht natcely see in conded.\n",
            "\n",
            "QUEEN ELIZABERT:\n",
            "Well, I dary I many 'tis the dimes!\n",
            "\n",
            "MARICHRANA:\n",
            "My the d \n",
            "\n",
            "[2m 12s (1250 62%) 1.6060]\n",
            "WhI't But one to the kinter,\n",
            "By this in your are worps, not to were and tiet's be firsest,\n",
            "Whow and th \n",
            "\n",
            "[2m 18s (1300 65%) 1.6630]\n",
            "What, and\n",
            "And cread not to my all.\n",
            "\n",
            "MENIUS:\n",
            "Hered thou a chimes, a wand both!\n",
            "\n",
            "Sesher bristain my his  \n",
            "\n",
            "[2m 23s (1350 67%) 1.8891]\n",
            "WhI conder to heart.\n",
            "Sie can thou rage ele loed to sis in gakes you he lear\n",
            "alf! Yourg, yor made: now, \n",
            "\n",
            "[2m 28s (1400 70%) 1.8279]\n",
            "What so deraked hopt:\n",
            "I prunterpes to to there that anare, and menstand,\n",
            "Dest the feirselmurfill hady  \n",
            "\n",
            "[2m 33s (1450 72%) 1.7542]\n",
            "Where appain. Which not I be will the well wind,\n",
            "That this from his my lader; my loth ment.\n",
            "\n",
            "DUKE VINC \n",
            "\n",
            "[2m 38s (1500 75%) 1.9019]\n",
            "What serent,\n",
            "That thou of I thand, you me your the\n",
            "sirr, Sis forder, for to her sis,\n",
            "rowning.\n",
            "\n",
            "ROMEO:\n",
            " \n",
            "\n",
            "[2m 44s (1550 77%) 1.8045]\n",
            "When, some the dime, and my bey hile me.\n",
            "\n",
            "PETBRUCKINGHABMNT:\n",
            "I did me eliverent, I done,\n",
            "Nay, my wish  \n",
            "\n",
            "[2m 49s (1600 80%) 1.8654]\n",
            "Whom make mering and have ever\n",
            "A my nat the betee, in thy sheart a'tise shat have bef-moround abours\n",
            "T \n",
            "\n",
            "[2m 54s (1650 82%) 1.5213]\n",
            "What as ar fands tost there bor groughat wife fealle of your fleal shaw\n",
            "What trath and shall 'twenks a \n",
            "\n",
            "[2m 59s (1700 85%) 2.3346]\n",
            "Why make with her him\n",
            "Litt, threan make: what a gray.\n",
            "\n",
            "Clize fay, many: in thy fair his some\n",
            "For the t \n",
            "\n",
            "[3m 4s (1750 87%) 1.7375]\n",
            "When die?\n",
            "\n",
            "ROMEO:\n",
            "To then, and well in are this it time\n",
            "to laid, Lord, the know the prothers pall them \n",
            "\n",
            "[3m 9s (1800 90%) 1.7436]\n",
            "When her beathice, percond the my mo truche, sistry's prouke.\n",
            "Where a my lovge, for you such is shat w \n",
            "\n",
            "[3m 14s (1850 92%) 2.0218]\n",
            "Where, with to pather re? Mayend in it\n",
            "Ceeven in sied with I lord hark not,\n",
            "And and de, all the deed,  \n",
            "\n",
            "[3m 19s (1900 95%) 1.6606]\n",
            "Whiving, live your did your platus hast hearty\n",
            "And all fore fie, I re fless, foof will saye: redse thi \n",
            "\n",
            "[3m 24s (1950 97%) 1.6410]\n",
            "What seempul ubbettred metred this are make,\n",
            "Thing ay and all the such heacher us to now the mauding s \n",
            "\n",
            "[3m 29s (2000 100%) 2.0058]\n",
            "Which like like as chours them?\n",
            "\n",
            "LADY SCAPULET:\n",
            "Go, Edward: whilk'd ould and Sin deam-versime grance m \n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 2000 # Number of epochs\n",
        "print_every = 50\n",
        "plot_every = 20\n",
        "hidden_size = 100\n",
        "n_layers = 1\n",
        "lr = 0.005\n",
        "\n",
        "# The input_size & output_size are the total number of n_characters\n",
        "rnn = RNN(n_characters, hidden_size, n_characters, n_layers) # The rnn variable consists of the return values from the RNN model\n",
        "\n",
        "# Optimize\n",
        "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train(*random_training_set())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "        print(evaluate('Wh', 100), '\\n')\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWhQGN73Z6D4"
      },
      "source": [
        "#### Plotting the Training Losses\n",
        "\n",
        "Plotting the historical loss from all_losses shows the network learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "aRMgqaJoZ6D8",
        "outputId": "1240abab-2919-49f3-ce12-b8e7a7d85af6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(all_losses)\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDMlqGtnZ6EF"
      },
      "source": [
        "### 5. Adapting or Tuning for Text Generation\n",
        "\n",
        "In the evaluate function above, every time a prediction is made, the outputs are divided by the \"temperature\" argument passed. Using a higher number makes all actions more equally likely, and thus gives us \"more random\" outputs. Using a lower value (less than 1) makes high probabilities contribute more. By turning the temperature towards zero you are choosing only the most likely outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hkcqnIlZ6EI"
      },
      "source": [
        "Let us see the effects of this by adjusting the temperature argument:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSwY7UOEZ6EK",
        "outputId": "f684769c-3652-4004-a452-e914b90ef4e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ud sage the look not ither branthing on thou,\n",
            "For no Sing? of as Sear excan llow the mornespasst I not in here corring lither cansubbes.\n",
            "Yune to his heave life spriadare the some,\n",
            "The do muss in deathe\n"
          ]
        }
      ],
      "source": [
        "print(evaluate('u', 200, temperature=0.8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIjNrZNSZ6ER"
      },
      "source": [
        "Lower temperatures are less varied, choosing only the more probable outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB_ntU41a74t",
        "outputId": "d6d009d3-5b1b-4689-8128-72bdc6f5a88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The done the make in the like and the heard here heard\n",
            "That the rey the heard the done the done the restion the reting as the broke and the have heard\n",
            "That some the shall be have he did the death the th\n"
          ]
        }
      ],
      "source": [
        "print(evaluate('Th', 200, temperature=0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80cSDcEXZ6EU"
      },
      "source": [
        "\n",
        "Higher temperatures more varied, choosing less probable outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXusqAsCZ6EV",
        "outputId": "067a22e0-bd11-45aa-f853-193c452e5a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how.\n",
            "In leave emland?-O the teme:\n",
            "I nots.\n",
            "3er-snsugo Cas mare lork Ee:\n",
            "Fronesh cormiom.\n",
            "\n",
            "TABELLABJREL:\n",
            "Sin, lode t sthap's disccietr; otch uqson: I do?r\n",
            "I timen do dry I,' by for, I gavinglis ans some yo\n"
          ]
        }
      ],
      "source": [
        "print(evaluate('how', 200, temperature=1.4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOkO2rwFZ6Eb"
      },
      "source": [
        "### Ungraded Exercise 1:\n",
        "\n",
        "Change the number of epochs to 1000. Calculate the time taken and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZzyyVD63dmJ",
        "outputId": "5dfa3cfb-4be7-4ca7-e372-0f96a10be92a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0m 5s (50 5%) 2.6308]\n",
            "Wh sow yomy\n",
            "As fond, fond\n",
            "I-o withescameond wihere,\n",
            "An wist ere heagsy hise to node bealAn ugaer, sour \n",
            "\n",
            "[0m 10s (100 10%) 2.3230]\n",
            "Whan wor\n",
            "ise ar sher she israd homen wert s as he not tis haved thod an dasde, angd, me.\n",
            "\n",
            "Fired macere \n",
            "\n",
            "[0m 15s (150 15%) 2.1376]\n",
            "Whe me;\n",
            "And wisth chan:\n",
            "A tlof yout of sist porn sou kon of she mat stadd ence will so your whead cour \n",
            "\n",
            "[0m 20s (200 20%) 2.0989]\n",
            "Who hadsesy you whad ham mady tho sthe thet Pine the cherery\n",
            "Andine the thed and and thes sto you spit \n",
            "\n",
            "[0m 25s (250 25%) 2.2566]\n",
            "Whild wheade bector howange\n",
            "\n",
            "MAHANED IIA:\n",
            "Thou not minive is doupen dentcome!\n",
            "The hade defed\n",
            "Um me you \n",
            "\n",
            "[0m 30s (300 30%) 2.2454]\n",
            "Who gonot the that and beat, and rouse juwer one he briend, and as I spides, with a roudss be eed sun  \n",
            "\n",
            "[0m 35s (350 35%) 1.9889]\n",
            "Whime for, I me deior in the of and the sopher treave then corthen demees rour at sold and not sour da \n",
            "\n",
            "[0m 40s (400 40%) 2.0146]\n",
            "Whremes frove all then word hemom hereles spoothat bed, and to your int thand standus fort and mang hi \n",
            "\n",
            "[0m 46s (450 45%) 2.0966]\n",
            "Wher from my misce deace.\n",
            "Lors Wheser my lisden;\n",
            "Is leases,\n",
            "Senain the come?\n",
            "That not your her domy ca \n",
            "\n",
            "[0m 51s (500 50%) 2.0697]\n",
            "Whining a come, and menge, in has of this ford areped his me hom more of the his monelfe, low thou sex \n",
            "\n",
            "[0m 56s (550 55%) 1.8288]\n",
            "Whst to shall he knoww the pold whated them his btt which heir in be my knoute, for sue for themert va \n",
            "\n",
            "[1m 1s (600 60%) 1.9955]\n",
            "Whisgh, have has re are me nor.\n",
            "\n",
            "LUCIUS:\n",
            "If to wheat wime to deever\n",
            "That our thir my grungs\n",
            "Yood yent  \n",
            "\n",
            "[1m 6s (650 65%) 1.8950]\n",
            "Whise of\n",
            "Drick his shest come an in thouse and hese stange\n",
            "'TExNall jlouse her her a prievings ming co \n",
            "\n",
            "[1m 11s (700 70%) 2.0790]\n",
            "Whercencperow a sirelfore, swory, I kinder on that then\n",
            "I dead Vo a dervencer deat!\n",
            "\n",
            "LIZARPETER:\n",
            "And y \n",
            "\n",
            "[1m 16s (750 75%) 1.7445]\n",
            "Whioloses of yet is sue beensherper a wister that on mear you to withimoy excions.\n",
            "\n",
            "KING ETRUCHIO:\n",
            "Han \n",
            "\n",
            "[1m 22s (800 80%) 2.1432]\n",
            "Whest the did crong I'll; in the sweelk, she prejister thatter them ourst sto so hemand,\n",
            "Re plemor of  \n",
            "\n",
            "[1m 27s (850 85%) 1.7653]\n",
            "What peler;\n",
            "Welt:\n",
            "I de, and all toue\n",
            "That the mary I common well as made I where I I weracer; I surbed \n",
            "\n",
            "[1m 32s (900 90%) 1.8091]\n",
            "Whe have be depont, to your hoasinst, look of he henglers denced\n",
            "That mady not ound brance all bater a \n",
            "\n",
            "[1m 36s (950 95%) 2.0552]\n",
            "Why, kind you houn:\n",
            "I'io slaim the that of the to thim moal.\n",
            "\n",
            "CLARENCE:\n",
            "I wort shall pair lother foul  \n",
            "\n",
            "[1m 42s (1000 100%) 2.0525]\n",
            "Whereforring my see sold a shall,\n",
            "This blow a good clorkinmelobreak:\n",
            "Which beases comound, man acond h \n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 1000 # Number of epochs\n",
        "print_every = 50\n",
        "plot_every = 20\n",
        "hidden_size = 100\n",
        "n_layers = 1\n",
        "lr = 0.005\n",
        "\n",
        "# The input_size & output_size are the total number of n_characters\n",
        "rnn = RNN(n_characters, hidden_size, n_characters, n_layers) # The rnn variable consists of the return values from the RNN model\n",
        "\n",
        "# Optimize\n",
        "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train(*random_training_set())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "        print(evaluate('Wh', 100), '\\n')\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn9ZeqjF3DB_"
      },
      "source": [
        "### Acknowledgement\n",
        "\n",
        "https://blog.owulveryck.info/2017/10/29/about-recurrent-neural-network-shakespeare-and-go.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtQo0EAjhkPb"
      },
      "source": [
        "# Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Qbj6VTNeO2br"
      },
      "outputs": [],
      "source": [
        "#@title State True or False: When we turn the temperature towards zero, it means that we are choosing only the most similar outputs. { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"True\" #@param [\"\",\"True\",\"False\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "outputs": [],
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Too Simple, I am wasting time\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "outputs": [],
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"Everything is good\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "outputs": [],
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "r35isHfTVGKc"
      },
      "outputs": [],
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "outputs": [],
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "outputs": [],
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzAZHt1zw-Y-",
        "outputId": "bd46e470-8397-479c-e886-ca24f732a2b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 2778\n",
            "Date of submission:  28 Aug 2022\n",
            "Time of submission:  15:41:19\n",
            "View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\n"
          ]
        }
      ],
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "U3W16_36_RNN_C_RJ.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}