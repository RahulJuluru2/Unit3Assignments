{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U3W14_27_Overfitting_Ants_Bees_PyTorch_A-RJ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulJuluru2/unit3assignments/blob/main/U3W14_27_Overfitting_Ants_Bees_PyTorch_A_RJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zSWyuZTlYS1"
      },
      "source": [
        "\n",
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU2MBx7JtTyP"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot3pfe3AtWaN"
      },
      "source": [
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* reduce overfitting using regularization method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDtOUGiIbwT2",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "ce8de6f4-fd0f-49db-c991-5138b21e4cc3"
      },
      "source": [
        "#@title Experiment Explanation Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"850\" height=\"480\" controls>\n",
        "  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/Walkthrough_Overfitting_Ants_Bees.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=\"850\" height=\"480\" controls>\n",
              "  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/Walkthrough_Overfitting_Ants_Bees.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35RBpSDUtYUm"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVIILnxWtcKA"
      },
      "source": [
        "### Description\n",
        "\n",
        "For this experiment we have choosen a dataset which is subset of Imagenet. We have taken images belonging to ants and bees. The dataset contains 244 training images and 153 validation images. \n",
        "\n",
        "![alt text]( https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/15.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiXPGTW_lgPr"
      },
      "source": [
        "## Setup Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6IbB-MBliAa"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2216842\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNFH7eLklj18"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"9959488784\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWC2d3i-DY4s",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a38bba81-6ee5-4ec2-daf8-7767a6e6d5df"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook  \n",
        "from IPython import get_ipython\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook=\"U3W14_27_Overfitting_Ants_Bees_PyTorch_A\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\") \n",
        "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/hymenoptera_data.zip\")\n",
        "    ipython.magic(\"sx unzip /content/hymenoptera_data.zip\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "    \n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "  \n",
        "  \n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "  \n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup() \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2216842&recordId=2311\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEeo3n0ElYS_"
      },
      "source": [
        "## Importing the required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ydf-Vi2P2r6"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKWUSRUQuwmW"
      },
      "source": [
        "## Defining Transformation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPjq8djgJY7v"
      },
      "source": [
        "image_size = (128,128)\n",
        "# Define Transformation for an image\n",
        "transformations = transforms.Compose([\n",
        "                         # YOUR CODE HERE to define transformations\n",
        "                        transforms.Resize(size=image_size),\n",
        "                        transforms.Grayscale(),\n",
        "                        transforms.ToTensor(), \n",
        "                        transforms.Normalize((0.5,), (0.5,))\n",
        "                  ])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM5nwIvuu2Nw"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "\n",
        "**torch.utils.data.DataLoader** class represents a Python iterable over a dataset, with following features.\n",
        "\n",
        "1. Batching the data\n",
        "2. Shuffling the data\n",
        "3. Load the data in parallel using multiprocessing workers.\n",
        "\n",
        "\n",
        "The batches of train and test data are provided via data loaders that provide iterators over the datasets to train our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OxC0CShJZZ7"
      },
      "source": [
        "batch_size = 100 \n",
        "train_set = datasets.ImageFolder('/content/hymenoptera_data/train', transform = transformations)\n",
        "trainloader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
        "\n",
        "val_set =  datasets.ImageFolder('/content/hymenoptera_data/val',transform = transformations)# YOUR CODE HERE for Val Image folder\n",
        "val_loader = torch.utils.data.DataLoader(val_set , batch_size=100,shuffle=True)# YOUR CODE HERE for Val dataloader"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_set)} , {len(val_set)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV6ExyMUbvXn",
        "outputId": "3cccf70a-027a-4303-b0d2-c3bff874eab6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "244 , 153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEYZoawOppFN"
      },
      "source": [
        "## Defining the Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEhqiDSmfE3C"
      },
      "source": [
        "Neural Networks are inherited from the nn.Module class.\n",
        "\n",
        "Now let us define a neural network. Here we are using two functions \\__init__ and forward function.\n",
        "\n",
        "In the \\__init__  function, we define the layers using the provided modules from the nn package. The forward function is called on the Neural Network for a set of inputs, and it passes that input through the different layers that have been defined. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEJHXJD0jTwD"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(16384,4096)\n",
        "        self.linear2 = nn.Linear(4096,1024)\n",
        "        self.linear3 = nn.Linear(1024,256)\n",
        "        self.linear4 = nn.Linear(256,10)\n",
        "        self.linear5 = nn.Linear(10,2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # YOUR CODE HERE to implement forward pass\n",
        "        out = x.view(x.shape[0],-1)\n",
        "        out = self.linear1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.linear3(out)\n",
        "        out = self.linear4(out)\n",
        "        out = self.linear5(out)\n",
        "        return out\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw3kD1Kjqvx_"
      },
      "source": [
        "## Calling the instances of the network\n",
        "\n",
        "Let us declare an object of class model, and make it a CUDA model if CUDA is available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_5p3NM4S9CR"
      },
      "source": [
        "# Instantiate the model\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# YOUR CODE HERE to instantiate the model and convert to cuda type\n",
        "model = Model().to(device)\n",
        "\n",
        "# YOUR CODE HERE to define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr = 0.001)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F75Z3ABdqvyY"
      },
      "source": [
        "## Training and Testing the model\n",
        "\n",
        "In Training Phase, we iterate over a batch of images in the train_loader. For each batch, we perform  the following steps:\n",
        "\n",
        "* First we zero out the gradients using zero_grad()\n",
        "\n",
        "* We pass the data to the model i.e. we perform forward pass by calling the forward()\n",
        "\n",
        "* We calculate the loss using the actual and predicted labels\n",
        "\n",
        "* Perform Backward pass using backward() to update the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG_e4hjdrgs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8edb37-c71b-4037-9d31-f59a718b6293"
      },
      "source": [
        "# No of Epochs\n",
        "epoch = 20\n",
        "\n",
        "# keeping the network in train mode\n",
        "model.train()\n",
        "train_losses,  train_accuracy = [], []\n",
        "val_losses , val_accuracy = [], []\n",
        "\n",
        "# Loop for no of epochs\n",
        "for e in range(epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    # Iterate through all the batches in each epoch\n",
        "    for images, labels in trainloader:\n",
        "\n",
        "      # Convert the image and label to gpu for faster execution\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Passing the data to the model (Forward Pass)\n",
        "      outputs = model(images)\n",
        "\n",
        "      # Calculating the loss\n",
        "      loss = criterion(outputs, labels)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # Performing backward pass (Backpropagation)\n",
        "      loss.backward()\n",
        "\n",
        "      # optimizer.step() updates the weights accordingly\n",
        "      optimizer.step()\n",
        "\n",
        "      # Accuracy calculation\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    val_loss = 0\n",
        "    val_correct = 0\n",
        "    with torch.no_grad():\n",
        "        # Loop through all of the validation set\n",
        "        for images, labels in val_loader:\n",
        "            # YOUR CODE HERE to pass the val_images to model, calculate error and accuracy \n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            val_output = model(images)\n",
        "\n",
        "            # Calculate the error\n",
        "            val_loss += criterion(val_output,labels)\n",
        "            _ , predicted = torch.max(val_output,1)\n",
        "            val_correct += (predicted == labels).sum()\n",
        "\n",
        "    train_losses.append(train_loss/len(train_set))\n",
        "    # YOUR CODE HERE to append val losses\n",
        "    val_losses.append(val_loss/len(val_set))\n",
        "\n",
        "    train_accuracy.append(100 * correct/len(train_set))\n",
        "    # YOUR CODE HERE to append val accuracy\n",
        "    val_accuracy.append(100*val_correct/len(val_set))\n",
        "    \n",
        "    print('epoch: {}, Train Loss:{:.6f} Validation Loss {:.6f}Train Accuracy: {:.2f}, Validation accuracy {:.2f} '.format(e+1,train_losses[-1], val_losses[-1], train_accuracy[-1], val_accuracy[-1]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, Train Loss:0.141116 Validation Loss 0.012532Train Accuracy: 52.87, Validation accuracy 50.33 \n",
            "epoch: 2, Train Loss:0.064449 Validation Loss 0.069439Train Accuracy: 51.23, Validation accuracy 43.79 \n",
            "epoch: 3, Train Loss:0.039170 Validation Loss 0.021061Train Accuracy: 55.74, Validation accuracy 62.75 \n",
            "epoch: 4, Train Loss:0.013878 Validation Loss 0.017761Train Accuracy: 55.33, Validation accuracy 43.14 \n",
            "epoch: 5, Train Loss:0.015412 Validation Loss 0.011219Train Accuracy: 54.10, Validation accuracy 57.52 \n",
            "epoch: 6, Train Loss:0.010589 Validation Loss 0.018743Train Accuracy: 56.15, Validation accuracy 47.06 \n",
            "epoch: 7, Train Loss:0.011166 Validation Loss 0.015262Train Accuracy: 61.89, Validation accuracy 53.59 \n",
            "epoch: 8, Train Loss:0.012272 Validation Loss 0.011077Train Accuracy: 63.52, Validation accuracy 56.86 \n",
            "epoch: 9, Train Loss:0.008163 Validation Loss 0.013187Train Accuracy: 62.30, Validation accuracy 46.41 \n",
            "epoch: 10, Train Loss:0.008377 Validation Loss 0.014032Train Accuracy: 68.03, Validation accuracy 56.86 \n",
            "epoch: 11, Train Loss:0.006784 Validation Loss 0.010562Train Accuracy: 72.13, Validation accuracy 52.29 \n",
            "epoch: 12, Train Loss:0.006712 Validation Loss 0.013196Train Accuracy: 78.69, Validation accuracy 59.48 \n",
            "epoch: 13, Train Loss:0.005894 Validation Loss 0.013931Train Accuracy: 79.92, Validation accuracy 52.29 \n",
            "epoch: 14, Train Loss:0.005710 Validation Loss 0.015325Train Accuracy: 79.51, Validation accuracy 51.63 \n",
            "epoch: 15, Train Loss:0.005941 Validation Loss 0.012594Train Accuracy: 77.05, Validation accuracy 50.98 \n",
            "epoch: 16, Train Loss:0.004790 Validation Loss 0.012031Train Accuracy: 84.43, Validation accuracy 52.94 \n",
            "epoch: 17, Train Loss:0.004698 Validation Loss 0.012282Train Accuracy: 84.84, Validation accuracy 59.48 \n",
            "epoch: 18, Train Loss:0.003933 Validation Loss 0.012761Train Accuracy: 85.66, Validation accuracy 50.98 \n",
            "epoch: 19, Train Loss:0.003175 Validation Loss 0.016242Train Accuracy: 89.75, Validation accuracy 47.06 \n",
            "epoch: 20, Train Loss:0.003036 Validation Loss 0.016639Train Accuracy: 88.93, Validation accuracy 49.02 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1338yNobnnZ"
      },
      "source": [
        "## Data Augmentation\n",
        "\n",
        "\n",
        "\n",
        "Diversity of data and a larger dataset is the easiest way to avoid overfitting of the model. Data augmentation allows you to increase the size of your dataset by performing processes like flipping, cropping, rotation, scaling and translation on the existing images. Data augmentation not only increases the dataset size but also exposes the model to different angles and lighting and reduces the bias in the dataset, thus avoiding chances of overfitting. \n",
        "\n",
        "Added two more transformations to the original data.\n",
        "\n",
        "\n",
        "*   Applied random rotation of $45^o$ using **`transforms.RandomRotation`**\n",
        "*   Applied vertical flip to the images using **`transforms.RandomVerticalFlip()`**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7hR9B_pbm2g"
      },
      "source": [
        "image_size = (128,128)\n",
        "transformations = transforms.Compose([\n",
        "                                transforms.Resize(image_size), \n",
        "                                transforms.Grayscale(),\n",
        "                                transforms.RandomRotation(45),\n",
        "                                transforms.RandomVerticalFlip(),\n",
        "                                transforms.ToTensor(), \n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                                ])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HdQKsm-bm2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc609c40-2ad4-476d-a2d7-abd25be2f6b4"
      },
      "source": [
        "batch_size = 100 \n",
        "\n",
        "# YOUR CODE HERE to load train and validaion data in batches\n",
        "train_set = datasets.ImageFolder('/content/hymenoptera_data/train',transform = transformations)\n",
        "trainLoader = torch.utils.data.DataLoader(train_set,batch_size=100,shuffle=True,num_workers=8)\n",
        "\n",
        "val_set = datasets.ImageFolder('/content/hymenoptera_data/val',transform = transformations)\n",
        "valLoader = torch.utils.data.DataLoader(val_set,batch_size=100,shuffle=True,num_workers=8)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHgEW9-RmdL1"
      },
      "source": [
        "## Regularization\n",
        "\n",
        "Dropouts: Regularization techniques prevent the model from overfitting by modifying the cost function. Dropout, on the other hand, prevents overfitting by modifying the network itself. Every neuron apart from the ones in the output layer is assigned a probability p of being temporarily ignored from calculations. p is also called dropout rate and is initialized to 0.2. Then, as each iteration progresses, the neurons in each layer with the highest probability get dropped. This results in creating a smaller network with each epoch. Since in each iteration, a random input value can be eliminated, the network tries to balance the risk and not to favour any of the features and reduces bias and noise. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZAiX592ZeoG"
      },
      "source": [
        "## Optimize the Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et6X_fnFGR3t"
      },
      "source": [
        "class Optimized_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Optimized_Model, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(16384,4096)\n",
        "        self.linear2 = nn.Linear(4096,1024)\n",
        "        self.linear3 = nn.Linear(1024,256)\n",
        "        self.linear4 = nn.Linear(256,10)\n",
        "        self.linear5 = nn.Linear(10,2)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "    def forward(self, x):\n",
        "        # YOUR CODE HERE to implement forward pass\n",
        "        out = x.view(x.shape[0],-1)\n",
        "        out = self.linear1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.linear3(out)\n",
        "        out = self.linear4(out)\n",
        "        out = self.linear5(out)\n",
        "        out = self.dropout(out)\n",
        "        return out\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au6wjEGWZADQ"
      },
      "source": [
        "## Initialize the optimized model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRMMDeiFWlOY"
      },
      "source": [
        "# Instantiate the model\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# YOUR CODE BELOW to instantiate model and define loss function and optimizer\n",
        "model2 = Model().to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model2.parameters(),lr = 0.001)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEmKN7nRvDwm"
      },
      "source": [
        "## Training the optimized model\n",
        "\n",
        "In Training Phase, we iterate over a batch of images in the train_loader. For each batch, we perform  the following steps:\n",
        "\n",
        "* First we zero out the gradients using zero_grad()\n",
        "\n",
        "* We pass the data to the model i.e. we perform forward pass by calling the forward()\n",
        "\n",
        "* We calculate the loss using the actual and predicted labels\n",
        "\n",
        "* Perform Backward pass using backward() to update the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt_oZCN3P8rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b1ecd5-81b6-4b88-d32f-e290a6a1bce1"
      },
      "source": [
        "# No of Epochs\n",
        "epoch = 20\n",
        "\n",
        "model2.train()\n",
        "train_losses_opt,  train_accuracy_opt = [], []\n",
        "val_losses_opt , val_accuracy_opt = [], []\n",
        "    \n",
        "for e in range(epoch):\n",
        "    otrain_loss = 0\n",
        "    ocorrect = 0\n",
        "    # Iterate through all the batches in each epoch\n",
        "    for images, labels in trainloader:\n",
        "      \n",
        "      # Convert the image and label to gpu for faster execution\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      \n",
        "      # Zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # YOUR CODE HERE to perform forward pass\n",
        "      outputs = model2(images)\n",
        "\n",
        "      # YOUR CODE HERE to Calculate the loss\n",
        "      loss = criterion(outputs,labels)\n",
        "      otrain_loss += loss.item()\n",
        "\n",
        "      # Performing backward pass (Backpropagation)\n",
        "      loss.backward()\n",
        "\n",
        "      # optimizer.step() updates the weights accordingly\n",
        "      optimizer.step()\n",
        "\n",
        "      # YOUR CODE HERE for accuracy calculation\n",
        "      _ , predicted = torch.max(outputs , 1)\n",
        "      ocorrect += (predicted == labels).sum().item()\n",
        "\n",
        "    oval_loss = 0\n",
        "    oval_correct = 0\n",
        "    with torch.no_grad():\n",
        "        # Loop through all of the validation set\n",
        "        for images, labels in val_loader:\n",
        "            # YOUR CODE HERE to pass the val_images to model, calculate error and accuracy \n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            val_output = model2(images)\n",
        "            oval_loss += criterion(val_output,labels)\n",
        "\n",
        "            _ , predicted = torch.max(val_output,1)\n",
        "            oval_correct += (predicted == labels).sum()\n",
        "\n",
        "    # YOUR CODE HERE to append all train, validation accuracy and losses\n",
        "    train_losses_opt.append(otrain_loss/len(train_set))\n",
        "    train_accuracy_opt.append(100 * ocorrect / len(train_set))\n",
        "\n",
        "    val_losses_opt.append(oval_loss/len(val_set))\n",
        "    val_accuracy_opt.append(100 * oval_correct / len(val_set))\n",
        "\n",
        "    print('epoch: {}, Train Loss:{:.6f} Test Loss {:.6f} Train Accuracy: {:.2f}, Test accuracy {:.2f} '.format(e+1,train_losses_opt[-1], val_losses_opt[-1], train_accuracy_opt[-1], val_accuracy_opt[-1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, Train Loss:0.071529 Test Loss 0.189298 Train Accuracy: 58.61, Test accuracy 42.48 \n",
            "epoch: 2, Train Loss:0.097264 Test Loss 0.053047 Train Accuracy: 49.59, Test accuracy 57.52 \n",
            "epoch: 3, Train Loss:0.036735 Test Loss 0.013529 Train Accuracy: 43.44, Test accuracy 56.21 \n",
            "epoch: 4, Train Loss:0.033349 Test Loss 0.023054 Train Accuracy: 60.25, Test accuracy 56.86 \n",
            "epoch: 5, Train Loss:0.026460 Test Loss 0.016639 Train Accuracy: 64.34, Test accuracy 60.13 \n",
            "epoch: 6, Train Loss:0.008713 Test Loss 0.014764 Train Accuracy: 72.95, Test accuracy 51.63 \n",
            "epoch: 7, Train Loss:0.007383 Test Loss 0.015220 Train Accuracy: 75.00, Test accuracy 60.78 \n",
            "epoch: 8, Train Loss:0.011376 Test Loss 0.011165 Train Accuracy: 63.11, Test accuracy 56.21 \n",
            "epoch: 9, Train Loss:0.008444 Test Loss 0.010444 Train Accuracy: 68.44, Test accuracy 54.25 \n",
            "epoch: 10, Train Loss:0.007544 Test Loss 0.010025 Train Accuracy: 69.67, Test accuracy 54.90 \n",
            "epoch: 11, Train Loss:0.006303 Test Loss 0.011670 Train Accuracy: 76.23, Test accuracy 51.63 \n",
            "epoch: 12, Train Loss:0.005255 Test Loss 0.011243 Train Accuracy: 78.69, Test accuracy 54.25 \n",
            "epoch: 13, Train Loss:0.004846 Test Loss 0.012376 Train Accuracy: 84.84, Test accuracy 53.59 \n",
            "epoch: 14, Train Loss:0.004850 Test Loss 0.012722 Train Accuracy: 82.79, Test accuracy 52.29 \n",
            "epoch: 15, Train Loss:0.003907 Test Loss 0.014635 Train Accuracy: 86.89, Test accuracy 56.21 \n",
            "epoch: 16, Train Loss:0.002975 Test Loss 0.014805 Train Accuracy: 88.93, Test accuracy 51.63 \n",
            "epoch: 17, Train Loss:0.002707 Test Loss 0.017867 Train Accuracy: 90.57, Test accuracy 54.25 \n",
            "epoch: 18, Train Loss:0.002214 Test Loss 0.018256 Train Accuracy: 91.80, Test accuracy 50.33 \n",
            "epoch: 19, Train Loss:0.001701 Test Loss 0.019556 Train Accuracy: 96.31, Test accuracy 53.59 \n",
            "epoch: 20, Train Loss:0.001904 Test Loss 0.019090 Train Accuracy: 94.67, Test accuracy 54.90 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goqw4VOf3u4h"
      },
      "source": [
        "# Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIzeiEtRh5nZ",
        "cellView": "form"
      },
      "source": [
        "#@title State True or False: Using dropout, random neurons in the layer gets deactivated at each training step\n",
        "Answer= \"TRUE\" #@param [\"\",\"TRUE\",\"FALSE\"]\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Was Tough, but I did it\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"Everything looks good\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r35isHfTVGKc"
      },
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d61018c-426e-40ab-8764-222ea9f096e1"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 2311\n",
            "Date of submission:  14 Aug 2022\n",
            "Time of submission:  19:06:56\n",
            "View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\n"
          ]
        }
      ]
    }
  ]
}